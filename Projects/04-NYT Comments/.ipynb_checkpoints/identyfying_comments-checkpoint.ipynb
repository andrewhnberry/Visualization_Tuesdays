{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's look into these comments and see if we can identify certain topics from it? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth',1000)\n",
    "#import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#NLP plugins required\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords \n",
    "\n",
    "\n",
    "#Topic Modeling \n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "\n",
    "#Import visualization tools for LDA models\n",
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "pyLDAvis.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>commentID</th>\n",
       "      <th>userDisplayName</th>\n",
       "      <th>userLocation</th>\n",
       "      <th>commentBody</th>\n",
       "      <th>recommendations</th>\n",
       "      <th>replyCount</th>\n",
       "      <th>replies</th>\n",
       "      <th>editorsSelection</th>\n",
       "      <th>recommendedFlag</th>\n",
       "      <th>isAnonymous</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>107400445</td>\n",
       "      <td>AACNY</td>\n",
       "      <td>New York</td>\n",
       "      <td>Not so \"peaceful\" in the Bronx last night.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>107400536</td>\n",
       "      <td>karen</td>\n",
       "      <td>florida</td>\n",
       "      <td>I was awaiting a huge bolt of lightening to explode over Trump while he was mishandling the Bible.</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  commentID userDisplayName userLocation  \\\n",
       "1      1  107400445           AACNY     New York   \n",
       "2      2  107400536           karen      florida   \n",
       "\n",
       "                                                                                          commentBody  \\\n",
       "1                                                          Not so \"peaceful\" in the Bronx last night.   \n",
       "2  I was awaiting a huge bolt of lightening to explode over Trump while he was mishandling the Bible.   \n",
       "\n",
       "   recommendations  replyCount replies  editorsSelection  recommendedFlag  \\\n",
       "1                1           0      []             False                0   \n",
       "2                2           0      []             False                0   \n",
       "\n",
       "   isAnonymous  \n",
       "1        False  \n",
       "2        False  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('nyt_comments.csv', index_col = 0)\n",
    "df[1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we're only doing topic modeling, we only just need the text column. In this case it's the commentBody."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "def tokenizer(text):\n",
    "    '''\n",
    "    Simple tokenizer:\n",
    "    1.) Removes stopwords\n",
    "    2.) Use Snowball stemmer\n",
    "    '''\n",
    "    \n",
    "    #Split each word up in text, which is a long string of words. \n",
    "    #These words are called tokens\n",
    "    \n",
    "    list_of_tokens = text.split(' ')\n",
    "    \n",
    "    #Let us use a stemmer\n",
    "    stemmer = SnowballStemmer(language = 'english')\n",
    "    \n",
    "    #list of cleaned_tokens\n",
    "    cleaned_tokens = []\n",
    "\n",
    "    #Remove Stopwords\n",
    "    for token in list_of_tokens:\n",
    "        if (not token in stop_words):\n",
    "            # Stemm words\n",
    "            token_stemmed = stemmer.stem(token)\n",
    "                \n",
    "            cleaned_tokens.append(token_stemmed)\n",
    "            \n",
    "    return cleaned_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instatiate TFIDF model\n",
    "tfidf = TfidfVectorizer(tokenizer = tokenizer, \n",
    "                           min_df = 25, \n",
    "                           ngram_range = (1,3), \n",
    "                           lowercase = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_matrix = tfidf.fit_transform(df.commentBody)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1336x300 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 17406 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If you would like to see the matrix in a dataframe form\n",
    "matrix_df = pd.DataFrame(token_matrix.toarray(),\n",
    "                        columns = tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>trump</th>\n",
       "      <th>-</th>\n",
       "      <th>--</th>\n",
       "      <th>across</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>actual</th>\n",
       "      <th>administr</th>\n",
       "      <th>...</th>\n",
       "      <th>white hous</th>\n",
       "      <th>without</th>\n",
       "      <th>wonder</th>\n",
       "      <th>word</th>\n",
       "      <th>work</th>\n",
       "      <th>world</th>\n",
       "      <th>would</th>\n",
       "      <th>year</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.161496</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.176041</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1331</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1332</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.191121</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>0.271932</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1336 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      trump         -   --  across  act  action  actual  \\\n",
       "0     0.000000  0.0     0.0  0.161496  0.0     0.0  0.0     0.0     0.0   \n",
       "1     0.000000  0.0     0.0  0.000000  0.0     0.0  0.0     0.0     0.0   \n",
       "2     0.000000  0.0     0.0  0.000000  0.0     0.0  0.0     0.0     0.0   \n",
       "3     0.000000  0.0     0.0  0.000000  0.0     0.0  0.0     0.0     0.0   \n",
       "4     0.000000  0.0     0.0  0.000000  0.0     0.0  0.0     0.0     0.0   \n",
       "...        ...  ...     ...       ...  ...     ...  ...     ...     ...   \n",
       "1331  0.000000  0.0     0.0  0.000000  0.0     0.0  0.0     0.0     0.0   \n",
       "1332  0.000000  0.0     0.0  0.000000  0.0     0.0  0.0     0.0     0.0   \n",
       "1333  0.000000  0.0     0.0  0.000000  0.0     0.0  0.0     0.0     0.0   \n",
       "1334  0.000000  0.0     0.0  0.000000  0.0     0.0  0.0     0.0     0.0   \n",
       "1335  0.271932  0.0     0.0  0.000000  0.0     0.0  0.0     0.0     0.0   \n",
       "\n",
       "      administr  ...  white hous   without  wonder  word  work  world  would  \\\n",
       "0           0.0  ...    0.000000  0.176041     0.0   0.0   0.0    0.0    0.0   \n",
       "1           0.0  ...    0.000000  0.000000     0.0   0.0   0.0    0.0    0.0   \n",
       "2           0.0  ...    0.000000  0.000000     0.0   0.0   0.0    0.0    0.0   \n",
       "3           0.0  ...    0.000000  0.000000     0.0   0.0   0.0    0.0    0.0   \n",
       "4           0.0  ...    0.000000  0.000000     0.0   0.0   0.0    0.0    0.0   \n",
       "...         ...  ...         ...       ...     ...   ...   ...    ...    ...   \n",
       "1331        0.0  ...    0.000000  0.000000     0.0   0.0   0.0    0.0    0.0   \n",
       "1332        0.0  ...    0.191121  0.000000     0.0   0.0   0.0    0.0    0.0   \n",
       "1333        0.0  ...    0.000000  0.000000     0.0   0.0   0.0    0.0    0.0   \n",
       "1334        0.0  ...    0.000000  0.000000     0.0   0.0   0.0    0.0    0.0   \n",
       "1335        0.0  ...    0.000000  0.000000     0.0   0.0   0.0    0.0    0.0   \n",
       "\n",
       "      year  yesterday  yet  \n",
       "0      0.0        0.0  0.0  \n",
       "1      0.0        0.0  0.0  \n",
       "2      0.0        0.0  0.0  \n",
       "3      0.0        0.0  0.0  \n",
       "4      0.0        0.0  0.0  \n",
       "...    ...        ...  ...  \n",
       "1331   0.0        0.0  0.0  \n",
       "1332   0.0        0.0  0.0  \n",
       "1333   0.0        0.0  0.0  \n",
       "1334   0.0        0.0  0.0  \n",
       "1335   0.0        0.0  0.0  \n",
       "\n",
       "[1336 rows x 300 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'matrix' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#I want 15 topics generated\n",
    "num_topics = 15\n",
    "\n",
    "#NMF Topic Modeling\n",
    "NMF_model = NMF(n_components = num_topics)\n",
    "NMF_model.fit(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NMF' object has no attribute 'components_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-e091d22942fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtoken_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtopic_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtopic_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopic\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNMF_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mtop_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtoken_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtopic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_words\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtop_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NMF' object has no attribute 'components_'"
     ]
    }
   ],
   "source": [
    "n_words = 15\n",
    "token_names = tfidf.get_feature_names()\n",
    "topic_list = []\n",
    "for topic_num, topic in enumerate(NMF_model.components_):\n",
    "    top_tokens = [token_names[i] for i in topic.argsort()][::-1][:n_words]\n",
    "    top_n = ' '.join(top_tokens)\n",
    "    topic_list.append(f\"topic_{'_'.join(top_tokens[:3])}\") \n",
    "    \n",
    "    print(f'Topic {topic_num}: {top_n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(topic_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using LDA Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 285 ms, sys: 138 ms, total: 423 ms\n",
      "Wall time: 3.07 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "                          evaluate_every=-1, learning_decay=0.7,\n",
       "                          learning_method='batch', learning_offset=10.0,\n",
       "                          max_doc_update_iter=100, max_iter=10,\n",
       "                          mean_change_tol=0.001, n_components=15, n_jobs=-1,\n",
       "                          perp_tol=0.1, random_state=None,\n",
       "                          topic_word_prior=None, total_samples=1000000.0,\n",
       "                          verbose=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#I want 15 topics generated\n",
    "num_topics = 15\n",
    "\n",
    "#instatiate LDA model\n",
    "lda_model = LDA(n_components = num_topics, n_jobs = -1)\n",
    "lda_model.fit(token_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: militari trump know say  it time protect get polic don't citi american never realli\n",
      "Topic 1: help much feder offic law enforc enforc law anyon civil american us outrag get arrest support\n",
      "Topic 2:  peopl trump polic need black vote year would like donald get mani american countri\n",
      "Topic 3:    care polic men cop last night georg - crimin without destroy follow away\n",
      "Topic 4: hear need burn ever polic turn left support action them. mani white fear govern like\n",
      "Topic 5: go must let see step happen i'm point way everyon report read white church time\n",
      "Topic 6: loot well now. last elect republican old nation tri anoth looter around november. vote \n",
      "Topic 7:  trump protest polic peac use peopl white right american militari presid need - order\n",
      "Topic 8: peopl follow free human good everyon busi go one protest offic respons think president. take\n",
      "Topic 9: one hope across offic polic still black can't end us get polic offic may country. least\n",
      "Topic 10: barr trump order wonder  that trump. got take person law long head look hand\n",
      "Topic 11: photo presid church trump  peac tear photo op op gas gass tear gas bibl clear first\n",
      "Topic 12: america state would unit unit state guard nation guard trump great people. sinc want nation presid democrat\n",
      "Topic 13: bibl hold man trump hous white hous yesterday hold bibl white someon church  front can't riot\n",
      "Topic 14: attorney general attorney general barr ask bring author crowd militari state thought word law order might\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "top_n_words = 15\n",
    "token_names = tfidf.get_feature_names()\n",
    "topic_list = []\n",
    "for topic_num, topic in enumerate(lda_model.components_):\n",
    "    top_tokens = [token_names[i] for i in topic.argsort()][::-1][:top_n_words] #Returns the indices that would sort an array\n",
    "    top_n = ' '.join(top_tokens) \n",
    "    topic_list.append(f\"topic_{'_'.join(top_tokens)}\") \n",
    "    \n",
    "    print(f'Topic {topic_num}: {top_n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Let us visualize these topics\n",
    "pyLDAvis.sklearn.prepare(lda, matrix, tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
